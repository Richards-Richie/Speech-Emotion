{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dande\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\dande\\anaconda3\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: librosa in c:\\users\\dande\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\dande\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dande\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Collecting keras\n",
      "  Using cached keras-3.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dande\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\dande\\anaconda3\\lib\\site-packages (7.31.1)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp39-cp39-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dande\\anaconda3\\lib\\site-packages (from keras) (1.4.0)\n",
      "Collecting rich (from keras)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\dande\\anaconda3\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\dande\\anaconda3\\lib\\site-packages (from keras) (3.7.0)\n",
      "Requirement already satisfied: optree in c:\\users\\dande\\anaconda3\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\dande\\anaconda3\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (63.4.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (3.0.20)\n",
      "Requirement already satisfied: pygments in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (2.17.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (0.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\dande\\anaconda3\\lib\\site-packages (from IPython) (0.4.5)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.38.0)\n",
      "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Using cached numba-0.59.1-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (4.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dande\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dande\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dande\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Using cached keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Using cached numba-0.59.1-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached llvmlite-0.42.0-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "Installing collected packages: llvmlite, h5py, google-pasta, gast, astunparse, rich, numba, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy librosa seaborn matplotlib keras scikit-learn IPython tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MnT3uo1KaWJ",
    "outputId": "2e790fda-489b-4918-c457-4a7dfcea9e1b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1384\\2579127733.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#IMPORT THE LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import keras\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import tensorflow as tf\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDzUZwlhHcw_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH-oVJvWHlco"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjuyd-LYKg5Y",
    "outputId": "69f7a8e5-de71-4ef2-a842-1a32c9985585"
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libsndfile1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26kNLdmTgDCp",
    "outputId": "b00745d1-c071-4270-cbe5-0b824edf0a9d"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjravBCYKrq4",
    "outputId": "da83eef8-f26f-4ff3-9b17-2498f06edaf9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ravdess = \"drive/MyDrive/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "ravdess_directory_list = os.listdir(ravdess)\n",
    "print(ravdess_directory_list)\n",
    "\n",
    "# Filter out files in .ipynb_checkpoints directory\n",
    "ravdess_directory_list = [file for file in ravdess_directory_list if not file.startswith('.ipynb_checkpoints')]\n",
    "\n",
    "# Access the remaining files\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPifFnawLnKH"
   },
   "outputs": [],
   "source": [
    "Crema = \"drive/MyDrive/kaggle/input/cremad/AudioWAV/\"\n",
    "Tess = \"drive/MyDrive/kaggle/input/toronto-emotional-speech-set-tess/TESS toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
    "Savee = \"drive/MyDrive/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W3OqPXjOn7M"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHkJeFfIRaaw"
   },
   "outputs": [],
   "source": [
    "file_emotion = []\n",
    "file_path = []\n",
    "for i in ravdess_directory_list:\n",
    "    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(ravdess+ i)\n",
    "    for f in actor:\n",
    "        part = f.split('.')[0].split('-')\n",
    "    # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(ravdess + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUzaUbqCSLbU",
    "outputId": "0acad2b1-dc58-4acc-a832-e7851d9703e7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Print the first element of the 'actor' list\n",
    "print(actor[0])\n",
    "\n",
    "# Print the first element of the 'part' list\n",
    "print(part[0])\n",
    "\n",
    "# Print the first element of the 'file_path' list\n",
    "print(file_path[0])\n",
    "\n",
    "# Convert the third element of the 'part' list to an integer and print it\n",
    "print(int(part[2]))\n",
    "\n",
    "# Print the value stored in the variable 'f'\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4hA0eQvUk5t",
    "outputId": "96768029-3858-407b-adfc-b61ac63a27f7"
   },
   "outputs": [],
   "source": [
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "# changing integers to actual emotions.\n",
    "ravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',\n",
    "                             8:'surprise'},\n",
    "                            inplace=True)\n",
    "print(ravdess_df.head())\n",
    "print(\"______________________________________________\")\n",
    "print(ravdess_df.tail())\n",
    "print(\"_______________________________________________\")\n",
    "print(ravdess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khinkhw3aOIU",
    "outputId": "cded6ad4-6c26-456a-8093-5d897f6fa26f"
   },
   "outputs": [],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()\n",
    "print(Crema_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyI3AJ1acRFm",
    "outputId": "8e399f67-d494-4958-b302-6d7a7aba0f56"
   },
   "outputs": [],
   "source": [
    "print(Tess)\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()\n",
    "print(Tess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kK1UZ9ykSVId",
    "outputId": "ab1fe6bb-1a79-4af3-b636-6f1fbd80d9b1"
   },
   "outputs": [],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()\n",
    "print(Savee_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CUU2D_CbSY3s",
    "outputId": "b3c7e705-430e-4566-99fc-52f6ea9a3cd3"
   },
   "outputs": [],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = pd.concat([ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "ZtI6muFySaGG",
    "outputId": "6de9374f-0ca0-4636-f438-de9c929f1e74"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure 'Emotions' is treated as a categorical variable\n",
    "data_path['Emotions'] = data_path['Emotions'].astype('category')\n",
    "\n",
    "# Specify the data parameter in countplot\n",
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(data=data_path, x='Emotions')\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sl0SPRGSafQ",
    "outputId": "9861a4b5-ed1c-48c3-f7bb-9aed5184df3a"
   },
   "outputs": [],
   "source": [
    "data,sr = librosa.load(file_path[0])\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "XTQuvBb9Sah6",
    "outputId": "61bce762-a46d-41ae-fd77-cae15eb72d6e"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "6TlxYwxHSalX",
    "outputId": "0dcd2de6-78bc-4959-fec9-75cf88d27d39"
   },
   "outputs": [],
   "source": [
    "# CREATE LOG MEL SPECTROGRAM\n",
    "plt.figure(figsize=(10, 5))\n",
    "spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000)\n",
    "log_spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(log_spectrogram, y_axis='mel', sr=sr, x_axis='time');\n",
    "plt.title('Mel Spectrogram ')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "vbHethiZSat1",
    "outputId": "4c683f0d-cd13-4779-e938-b0632a206799"
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)\n",
    "\n",
    "\n",
    "# MFCC\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcddfDmiSava"
   },
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "7aHlFUGbSaxn",
    "outputId": "80b3a321-13ba-4364-8465-fe8aa5d6c7e7"
   },
   "outputs": [],
   "source": [
    "# NORMAL AUDIO\n",
    "\n",
    "\n",
    "import librosa.display\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=data, sr=sr)\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "9zKjLbvISayy",
    "outputId": "b8f88f74-70cc-4d7e-e328-10c09f1843de"
   },
   "outputs": [],
   "source": [
    "# AUDIO WITH NOISE\n",
    "x = noise(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDG6M0xlSa1F",
    "outputId": "70e8bce1-8beb-45aa-d2a3-f67b86d575f4"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64HlRy73Sa4n",
    "outputId": "e90788fa-b8a3-4efb-b5d7-f80ff739381f"
   },
   "outputs": [],
   "source": [
    "pip show librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "_KrlXR_JS65V",
    "outputId": "f0f02dfc-716c-4c99-86c0-c5eead0c6172"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(y=data, rate=rate)\n",
    "\n",
    "# Assuming 'data' and 'sr' are already defined\n",
    "x = stretch(data)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "JOTgoZ0IS67z",
    "outputId": "015696c1-31eb-4229-afc7-203087ac2175"
   },
   "outputs": [],
   "source": [
    "# SHIFTED AUDIO\n",
    "x = shift(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "vyIh3hRSS69H",
    "outputId": "6d912696-4c74-48c9-c1ff-ce496e751f0d"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=pitch_factor)\n",
    "\n",
    "# Assuming 'data' and 'sr' are already defined\n",
    "x = pitch(data, sr)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J52CbyLHS7A6"
   },
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "\n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result\n",
    "\n",
    "def get_features(path,duration=2.5, offset=0.6):\n",
    "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
    "    aud=extract_features(data)\n",
    "    audio=np.array(aud)\n",
    "\n",
    "    noised_audio=noise(data)\n",
    "    aud2=extract_features(noised_audio)\n",
    "    audio=np.vstack((audio,aud2))\n",
    "\n",
    "    pitched_audio=pitch(data,sr)\n",
    "    aud3=extract_features(pitched_audio)\n",
    "    audio=np.vstack((audio,aud3))\n",
    "\n",
    "    pitched_audio1=pitch(data,sr)\n",
    "    pitched_noised_audio=noise(pitched_audio1)\n",
    "    aud4=extract_features(pitched_noised_audio)\n",
    "    audio=np.vstack((audio,aud4))\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUEu3eJkS7Ee",
    "outputId": "7b35c2bf-079f-465e-e2e1-31505cd7ea13"
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZIPOka3S7Ht",
    "outputId": "7b79eecd-4da0-40d6-b065-df8a076399f2"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming your get_features, zcr, rmse, and noise functions are defined somewhere\n",
    "\n",
    "def extract_features(data, sr=22050, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        my_mfcc(data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "                        ))\n",
    "    return result\n",
    "\n",
    "def my_mfcc(data, sr, n_fft=2048, hop_length=512, flatten: bool = True):\n",
    "    mfcc_result = librosa.feature.mfcc(y=data, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    return np.squeeze(mfcc_result.T) if not flatten else np.ravel(mfcc_result.T)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for index, (path, emotion) in tqdm(enumerate(zip(data_path.Path, data_path.Emotions))):\n",
    "    features = get_features(path)\n",
    "\n",
    "    for i in features:\n",
    "        X.append(i)\n",
    "        Y.append(emotion)\n",
    "\n",
    "    if index % 500 == 0:\n",
    "        tqdm.write(f'{index} audio has been processed')\n",
    "\n",
    "print('Done')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVTyC5SrS7J1",
    "outputId": "363182e3-3166-4b06-8c07-58a40c05a923"
   },
   "outputs": [],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "LDvuc3chS7NZ",
    "outputId": "eac0ed1c-6f19-44b5-ce7d-16f8d745c34d"
   },
   "outputs": [],
   "source": [
    "Emotions = pd.DataFrame(X)\n",
    "Emotions['Emotions'] = Y\n",
    "Emotions.to_csv('emotion.csv', index=False)\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "IKZ63MbDTkS2",
    "outputId": "9d5f6c4a-f8f1-406d-c0f8-09f9ef8a1268"
   },
   "outputs": [],
   "source": [
    "Emotions = pd.read_csv('./emotion.csv')\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fWvZl6sTkT3",
    "outputId": "034ec01d-9b15-4401-dd06-556dc0d8e33b"
   },
   "outputs": [],
   "source": [
    "print(Emotions.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxakE4BSTkWN",
    "outputId": "c1dc50f7-5c43-432d-ba95-ae45e0274c78"
   },
   "outputs": [],
   "source": [
    "Emotions=Emotions.fillna(0)\n",
    "print(Emotions.isna().any())\n",
    "Emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJj_8KtvTkXe",
    "outputId": "76df4653-7342-4e52-990f-bb1beae93ca5"
   },
   "outputs": [],
   "source": [
    "np.sum(Emotions.isna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-dYZkncTka_"
   },
   "outputs": [],
   "source": [
    "X = Emotions.iloc[: ,:-1].values\n",
    "Y = Emotions['Emotions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp7aeZnqTkc_"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBp8Z1INTkgI",
    "outputId": "5961c8a4-fb4e-415d-e382-59930dd2c086"
   },
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRKqJv7FTkjl",
    "outputId": "f64fb200-dde4-45b9-cfa1-8764f4e3ee8f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42,test_size=0.2, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXgJdVRvTklG"
   },
   "outputs": [],
   "source": [
    "#reshape for lstm\n",
    "X_train = x_train.reshape(x_train.shape[0] , x_train.shape[1] , 1)\n",
    "X_test = x_test.reshape(x_test.shape[0] , x_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IaQ42XObTkoj",
    "outputId": "8d0822a6-c84b-4033-a859-e335f65f64f6"
   },
   "outputs": [],
   "source": [
    "# scaling our data with sklearn's Standard scaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3CJx_hGUVtD"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INQPK2oeUVvn"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "model_checkpoint = ModelCheckpoint('drive\\MyDrive\\Kaggle\\working\\best_model1_weights.h5', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yB3N-XhUVyT"
   },
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_acc',mode='auto',patience=5,restore_best_weights=True)\n",
    "lr_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUNpd9VbUV0o",
    "outputId": "abadc1e5-2b11-493d-a513-9974e6f51af0"
   },
   "outputs": [],
   "source": [
    "#Reshape for CNN_LSTM MODEL\n",
    "\n",
    "x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape\n",
    "#x_testcnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLOULGtOUV23",
    "outputId": "11c7e109-bb82-43d9-aa7d-6c9115457aec"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    L.Conv1D(512,kernel_size=5, strides=1,padding='same', activation='relu',input_shape=(X_train.shape[1],1)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "\n",
    "    L.Conv1D(512,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the second max pooling layer\n",
    "\n",
    "    L.Conv1D(256,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "\n",
    "    L.Conv1D(256,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the fourth max pooling layer\n",
    "\n",
    "    L.Conv1D(128,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=3,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the fifth max pooling layer\n",
    "\n",
    "    L.Flatten(),\n",
    "    L.Dense(512,activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.Dense(7,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht8y4emNUV4U",
    "outputId": "d8bc9308-cad9-4b3d-a405-f2e0c55207e5"
   },
   "outputs": [],
   "source": [
    "history=model.fit(x_traincnn, y_train, epochs=30, validation_data=(x_testcnn, y_test), batch_size=64,callbacks=[early_stop,lr_reduction,model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "9iNX8FdQUV7V",
    "outputId": "bc7d0444-6d2b-4222-bd95-9eedd7011ad6"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(30)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "z4fzFZs2UV9g",
    "outputId": "5e4c2fb4-e28a-40c3-c668-f7e8c05ce3ff"
   },
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test0 = model.predict(x_testcnn)\n",
    "y_pred0 = encoder.inverse_transform(pred_test0)\n",
    "y_test0 = encoder.inverse_transform(y_test)\n",
    "\n",
    "# Check for random predictions\n",
    "df0 = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df0['Predicted Labels'] = y_pred0.flatten()\n",
    "df0['Actual Labels'] = y_test0.flatten()\n",
    "\n",
    "df0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "QzOEsb_8UWA5",
    "outputId": "a5a9d0ac-a310-4c0f-ccee-a22a37929ad9"
   },
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZXRcLTtRUWDt",
    "outputId": "6048f8e6-142f-494c-9c28-6eef7cf08f36"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test0, y_pred0)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()\n",
    "print(classification_report(y_test0, y_pred0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjDtBixsUWHf",
    "outputId": "ebaccec4-07b5-42fd-a1fd-42e4b5c1ec3a"
   },
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"drive/MyDrive/kaggle/working/CNN_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"drive/MyDrive/kaggle/working/CNN_model_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ithb8qaOUWK7",
    "outputId": "d3ae8f28-2a86-4153-d445-6db79583eb87"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "json_file = open('drive/MyDrive/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"drive/MyDrive/kaggle/working/best_model1_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYgOablpUWL9",
    "outputId": "799c2d82-c30d-4978-b013-21445425f22d"
   },
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn,y_test)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yg5hbiB_UWNg",
    "outputId": "8b44a590-4d0a-4357-9b0d-476ff58cd75a"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving scaler\n",
    "with open('drive/MyDrive/kaggle/working/scaler2.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Loading scaler\n",
    "with open('drive/MyDrive/kaggle/working/scaler2.pickle', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "\n",
    "# Saving encoder\n",
    "with open('drive/MyDrive/kaggle/working/encoder2.pickle', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# Loading encoder\n",
    "with open('drive/MyDrive/kaggle/working/encoder2.pickle', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihRu9iNuUWRA",
    "outputId": "c35bc653-2793-4472-f1cf-b3efd649cf51"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "json_file = open('drive/MyDrive/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"drive/MyDrive/kaggle/working/best_model1_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asOiCBk7VBQU",
    "outputId": "64eec98e-3f53-47b3-f73e-834fbc45d9dc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('drive/MyDrive/kaggle/working/scaler2.pickle', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "\n",
    "with open('drive/MyDrive/kaggle/working/encoder2.pickle', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8KQR_KwVBRd"
   },
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Udorczu1VBTr"
   },
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "\n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2NrZjlBVBXP"
   },
   "outputs": [],
   "source": [
    "def get_predict_feat(path):\n",
    "    d, s_rate= librosa.load(path, duration=2.5, offset=0.6)\n",
    "    res=extract_features(d)\n",
    "    result=np.array(res)\n",
    "    result=np.reshape(result,newshape=(1,2376))\n",
    "    i_result = scaler2.transform(result)\n",
    "    final_result=np.expand_dims(i_result, axis=2)\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVw_XH_jVBan"
   },
   "outputs": [],
   "source": [
    "# def rmse(data, frame_length=2048, hop_length=512):\n",
    "#     rmse = librosa.feature.rms(data, frame_length=frame_length, hop_length=hop_length)\n",
    "#     return np.squeeze(rmse)\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rms_values = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rms_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjWubBM3VOOR"
   },
   "outputs": [],
   "source": [
    "emotions1={1:'Neutral', 2:'Calm', 3:'Happy', 4:'Sad', 5:'Angry', 6:'Fear', 7:'Disgust',8:'Surprise'}\n",
    "def prediction(path1):\n",
    "    res=get_predict_feat(path1)\n",
    "    predictions=loaded_model.predict(res)\n",
    "    y_pred = encoder2.inverse_transform(predictions)\n",
    "    print(y_pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bosp4ePPVOQp"
   },
   "outputs": [],
   "source": [
    "def mfcc(data, sr, frame_length=2048, hop_length=512, flatten=True):\n",
    "    mfcc_result = librosa.feature.mfcc(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(mfcc_result.T) if not flatten else np.ravel(mfcc_result.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMr_z6AHVOTE",
    "outputId": "667eec20-46c2-4dd2-9681-f8927730833d"
   },
   "outputs": [],
   "source": [
    "prediction(\"drive/MyDrive/kaggle/Test/t1.m4a\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
